import k8s from '@kubernetes/client-node';
import amqp from 'amqplib';
import fs from 'fs';
import { Validator } from 'jsonschema';
import path from 'path';
import express from 'express';
import pg, { ClientConfig } from 'pg';
import JobSpec from './jobSpec.js';
import * as url from 'url';

const app = express();
app.use(express.json());

console.log(process.env);

let pgConf: ClientConfig = {
  host: process.env.PG_HOST,
  port: Number.parseInt(process.env.PG_PORT!),
  user: process.env.PG_USER,
  password: process.env.PG_PASSWORD,
  database: process.env.PG_DATABASE
}

console.log(pgConf);

const client = new pg.Client(pgConf);
client.connect().then(() => {
  console.log('Connected to Postgres')
});

const __dirname = url.fileURLToPath(new URL('.', import.meta.url));
const schema = JSON.parse(fs.readFileSync(path.join(__dirname, 'jobSpecSchema.json')).toString());
const validator = new Validator();

app.post('/job', async (req, res) => {
  try {
    // Validate input against the JobSpec schema
    // (autogenerated from the TypeScript interface).
    const vRes = validator.validate(req.body, schema);
    if (!vRes.valid) {
      console.log('Input job spec is invalid');
      for (let error of vRes.errors) {
        console.log(error);
      }
      process.exit(1);
    }
    let jobSpec = req.body as JobSpec;
    console.log('Read valid job spec');
    console.log(jobSpec);

    // Create a job in the database
    const result = await client.query('INSERT INTO job (name, start_time, completed, job_config) VALUES ($1, $2, $3, $4) RETURNING id', [jobSpec.jobName, new Date(), false, jobSpec]);
    const jobId = result.rows[0].id;
    // const jobId = 1;

    console.log(`Created job ${jobId} in postgres`);

    // Create configs for individual crawls
    let crawlMessages = [];
    for (let crawlSpec of jobSpec.crawls) {
      // Messages to put in the queue, to be consumed by crawler. Implements
      // the CrawlerFlags interface.
      // TODO: generate crawlIds here to simplify retry handling?
      let message = {
        "jobId": jobId,
        "name": crawlSpec.crawlName,
        "outputDir": jobSpec.dataDir,
        // "pgConf": jobSpec.pgConf,
        "crawlListFile": crawlSpec.crawlListFile,
        "crawlListHasReferrerAds": crawlSpec.crawlListHasReferrerAds,
        "chromeOptions": {
          "profileDir": crawlSpec.profileDir,
        },
        // TODO: also allow individual crawls to override crawl/scrape options if
        // we want to include different types of crawls?
        "crawlOptions": jobSpec.crawlOptions,
        "scrapeOptions": jobSpec.scrapeOptions
      };

      crawlMessages.push(message);
    }
    console.log(`Generated ${crawlMessages.length} crawl nessages`);


    // Modify job.yaml with correct number of completions needed
    // Set completions to the number of profiles in the job spec
    // Set parallelism to the user-requested parameter

    // .spec.completions = crawlMessages.length
    // .spec.parallelism = job.maxWorkers
    // .metadata.name = job-${job.jobName}
    // .template.metadata.name = crawl-${job.jobName}


    // Fill message queue with crawl configs
    const amqpConn = await amqp.connect(process.env.BROKER_URL!);
    const amqpChannel = await amqpConn.createChannel();
    await amqpChannel.assertQueue(process.env.QUEUE!);
    for (let message of crawlMessages) {
      amqpChannel.sendToQueue(process.env.QUEUE!, Buffer.from(JSON.stringify(message)));
    }

    console.log('Crawl messages sent to message queue');

    // Programmatically create Kubernetes job
    const kc = new k8s.KubeConfig();
    kc.loadFromDefault();
    const batchApi = kc.makeApiClient(k8s.BatchV1Api);

    let job = k8s.loadYaml(fs.readFileSync('./job.yaml').toString()) as k8s.V1Job;
    job.spec!.parallelism = jobSpec.maxWorkers;
    job.spec!.completions = crawlMessages.length;
    console.log('Read job YAML config');
    console.log('Running job...');
    await batchApi.createNamespacedJob('default', job);
    console.log('Job sent to k8s successfully');
    res.status(200).send();
  } catch (e) {
    console.log(e);
    res.status(500).send(e);
  }
});

app.listen(80, () => { console.log('Job server listening on port 80')});
